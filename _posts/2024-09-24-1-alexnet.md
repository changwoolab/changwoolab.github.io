---
layout: post
title: "Paper Review 1: ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)"
date: 2024-07-29 19:31:29 +0900
categories: paper-review
---

## The Impact of AlexNet

- Shows the possibility of “DEEP & LARGE” convolutional neural network that it could results in high quality precision
  - “DEPTH is important for achieving results”

## Architecture

![Image](/public/img/alexnet.png)

## Reducing Overfitting

1. **Data Augmentation**
   1. Extracting random 224 x 224 patches from 256 x 256 images
   2. Altering intensities of RGB channels (Perform PCA on RGB pixel values)
   - Computationally free → Compute on CPU while training on GPU
2. **Dropout**
   - Reason why Dropout reduces overfitting
     - → Reduces complex co-adaptations of neurons because **a neuron cannot rely on the presence of particular other neurons**

## Questions

모델의 성능을 높이는 데에 데이터 양도 중요하다고하고, 오버피팅을 줄이는 데에도 데이터 양이 중요하다고 하는데, 정확하게 데이터 양과 bias / Variance 의 관계를 잘 모르겠음

### 일반적으로

- **Bias = 모델 자체의 복잡성과 관련 있음. 모델이 복잡할수록 복잡한 패턴을 잡아낼 수 있음**
  - 데이터가 증가해도 분포가 같으면, 해당 데이터를 통해 학습할 수 있는 패턴이 그대로이므로,
    같은 모델을 썼을 때 Bias는 크게 변하지 않음
- Variance = 데이터가 많을수록 Generalization을 더 잘하게 됨 → Overfitting 방지

### 하지만 데이터들을 수집하며, 데이터셋의 분포가 변한다면!

- 모델이 더 많은 데이터를 기반으로 다른 패턴을 학습 → Bias 감소 가능!

### Data Augmentation이 Variance를 줄이는 이유

Cropping하고, Altering intensities of RGB Channels 해도 **해당 이미지의 “근본적인 패턴”은 변하지 않음.**
따라서 Augmentation은 같은 분포이지만 다른 Data 양을 늘려주므로, Variance를 줄여 Overfitting 방지
